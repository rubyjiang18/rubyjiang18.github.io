---
title: 'Notes of 推荐系统公开课 by Shusen Wang'
date: 2024-06-07
permalink: /posts/2024/06/blog-post-4/
tags:
  - learning
  - career
---

Disclaimer: The content herein is sourced from Shusen Wang's YouTube Channel, specifically the Playlist titled [Recommendation System]((https://www.youtube.com/playlist?list=PLvOO0btloRntAi-VnV06M1Bu0X1xljUUP)). This post is intended for personal study purposes.

------

[1 概要](#概要)  
[2 召回](#召回)  
[3 排序](#排序)  
[4 特征交叉](#特征交叉)  
[5 行为序列](#行为序列)  
[7 物品冷启](#物品冷启)  
[8 涨指标的方法](#涨指标)  

------

## <span>概要</span><a id="概要"></a>
### <span style="font-size:smaller; color:LightCoral">概要01</span> 推荐系统的基本概念
转化流程
```
曝光（Impression） --> 点击（Click） --> 滑动到底(ScrowToEnd), 点赞(Like), 收藏(Collect), 转发(Share) --> 评论(Comment)
```

（短期）消费指标：
- 点击率 = 点击次数 / 曝光次数
- 点赞率 = 点赞次数 / 点击次数
- 收藏率 = 收藏次数 / 点击次数
- 转发率 = 转发次数 / 点击次数
- 阅读完成率 = 滑动到底次数 / 点击次数 $\times f$(笔记长度) 

虽然点击率是重要的优化指标，但不能是唯一的指标，否则骗点击的标题就会泛滥。其他指标也可以反映出用户对笔记的兴趣。
$f$(笔记长度) 是一个归一化的函数，这是因为笔记越长，完成阅读的比例就越低。如果没有这个归一化的函数，对长笔记不公平。
注意：一味追求短期消费指标是不对的。举个例子，如果推荐算法只看用户短期兴趣，推很多用户最近感兴趣的内容，这些消费指标上涨，这样的坏处是会竭泽而渔，用户会很快失去兴趣，不再回来；反过来，如果把多样性做好，尝试一些用户没看过的话题，那么点击率不会上涨，但是会有利于提高用户粘性，留住用户，让用户更活跃。

衡量推荐系统的好坏，最重要的指标叫北极星指标，即最关键的指标，是衡量推荐系统好坏的根本标准。

北极星指标
- 用户规模：DAU， MAU
- 消费：人均使用推荐的时长，人均阅读笔记的数量
- 发布：发布渗透率、人均发布量

实验流程
- 离线实验 
    - 收集历史数据，在历史数据上做训练、测试。算法没有部署到产品中，没有跟用户交互。
    - 结果有参考价值，但没有线上实验可靠，也无法得到线上指标。
- 小流量AB测试
    - 算法部署到实际产品中，用户实际跟算法做交互。
    - 可以得到线上指标，如北极星指标。
- 全流量上线

### <span style="font-size:smaller; color:LightCoral">概要02</span> 推荐系统的链路
```
--几亿物品--> 召回 --几千物品--> 粗排 --几百物品--> 精排 --几百物品--> 重排 --几十物品-->
```

- 召回
    - 当用户刷新小红书时，系统会同时调用几十条召回通道，每条召回通道取几十到几百笔记，一共取几千篇笔记
- 粗排
    - 用规模比较小的机器学习模型给几千篇笔记逐一打分，按照分数做排序和截断，保留分数最高的几百篇笔记
- 精排
    - 这里要用大规模的神经网络为几百篇笔记逐一打分，精排的分数反映出用户对笔记的兴趣
    - 精排之后，可以做截断，也可以不做截断。小红书的精排不做截断，几百篇笔记都带着精排分数进入重排
- 重排
    - 重排是最后一步，根据精排分数和多样性分数做随机抽样，得到几十篇笔记
    - 然后把相似内容打散，并且插入广告和运营内容
    - 重拍的规则非常复杂，有好几千行代码

粗排、精排的NN输入是用户特征，物品特征，和统计特征，NN输出点预估的击率，点赞率，收藏率，转发率。融合（加权和）预估值得到最终的排序分数。这个值会决定笔记是否会被展示给用户，靠前或靠后。重排最重要的是做多样性抽样，比如MMR、DPP，从几百篇中选出几十篇。抽样的时候有两个依据，一个是精排分数的大小，一个是多样性。做完抽样后，用规则打散相似笔记，我们不能把内容过于相似的笔记排在相邻的位置上。重排的另一个目的是插入广告、运营推广内容，根据生态要求调整排序，比如不能连着出美女图片。召回和粗排是最大的漏斗，它们让候选笔记的数量从几亿变成几千然后变成几百。当候选笔记之后几百才能用大规模NN做精排，用DPP做抽样。

### <span style="font-size:smaller; color:LightCoral">概要03</span> 推荐系统的AB测试

算法工程师的日常工作就是改进算法的策略，目标是提高推荐系统的业务指标。所有对模型的粗略的改进都需要进行线上的AB测试，用实验数据来验证试验策略是否有效。举个例子解释AB测试的目的是什么：
- 召回团队实现了一种GNN召回通道，离线实验结果正向。但是离线实验的指标有提升未必意味着线上实验也会有收益。
- 做完离线实验，下一步是做线上的小流量AB测试，考察新的召回通道对线上指标的影响，比如DAU，留存，交互等。
- 除了上述目的，模型中的一些参数，比如GNN的深度取值（1，2，3），需要用AB测试选取最优参数。可以同时开三组AB测试，哪组效果好用哪个。

做AB测试需要对用户做随机分桶，比方说：
- 分$b=10$个桶，每个桶中有10%的用户。如果用户的数量足够大，那么每个桶DAU，留存，点击率这些指标都是相等的。
- 首先用哈希函数把用户ID映射成某个区间内的整数，然后把这些整数随机分成$b$个桶。
- 以GNN为例，一号桶实验组#1，以此类推，四号桶为对照组
- 计算每个桶的业务指标，比如DAU，人均使用推荐的时长，点击率等。
- 如果某个实验组指标显著优于对照组，则说明对应的策略有效，值得推全，即把流量扩大到100%。

接下来讲**分层实验**，用业界实际上就是这么做的。分层实验的目标就是解决流量不够用的问题。举个例子解释，比方说小红书有很多个部门，每个部门有好几个团队，负责推荐系统（召回，粗排，精排，重排），用户界面，广告，所有团队同时需要做实验，线上需要做几十个甚至上百个实验。如果把用户随机分成10组，1组作对照，9组作实验，那么只能同时做9组实验，根本无法满足产品迭代的需求。解决方案就是分层实验：
- 把实验分成很多层，比如召回，粗排，精排，重排，用户界面，广告，...
- 同层是实验之间需要互斥：比如GNN实验占了召回层的4个桶，其他召回实验只能用剩余的6个桶。同层互斥的目的是避免一个用户同时被两个召回实验影响。如果两个实验相互干扰，实验结果会变的不可控。
- 不同层之间流量正交：每一层都独立随机对用户做分桶。每一层都可以独立用100%的用户做实验。召回和粗排的用户是独立随机划分的，召回的2号桶和粗排的2号桶交集很小。
- 分层实验参考文献 Tang et al. Overlapping experiment infrastructure: more, better, faster experimentation. In KDD, 2020. [PDF](https://dl.acm.org/doi/pdf/10.1145/1835804.1835810) 

举个例子，召回层和精排层各自独立随机把用户分成10个桶：
- 召回层把用户分成10个桶：$u_1, u_2, ..., u_{10}$
- 精排层把用户分成10个桶：$v_1, v_2, ..., v_{10}$
- 设系统一共有$n$个用户，那么$\lvert u_i \rvert=\lvert v_j \rvert=n/10$
- 召回桶$u_i$和召回桶$u_j$的交集为$u_i \cap u_j=\varnothing$，即同层互斥，两个召回实验不会同时作用到同一用户上。
- 召回桶$u_i$和精排桶$v_j$的交集的大小为$\lvert u_i \cap v_j \rvert =n/100$。一个用户不能同时被两个召回实验影响，但可以同时受一个召回实验和一个精排实验影响。一个召回实验和一个精排实验各自作用在$n/10$个用户上，那么有$n/100$的用户同时被召回实验和精排实验影响，即不同层正交。

互斥 vs 正交：
- 如果所有实验都正交，则可以同时做无数组实验。
- 同类的策略（例如精排模型的两种结构）天然互斥，对于一个用户，只能用其中一种。
- 同类的策略（例如添加两条召回通道）效果会相互增强（1+1>2）。互斥可以避免同类策略相互干扰。
- 不同类型的策略（例如添加召回通道、优化粗排模型）通常不会相互干扰（1+1=2），可以作为正交的两层。

前面讲了AB测试的原理和分层实验，接下来介绍**holdout机制**：
- 每个实验（召回，粗排，精排，重排）独立汇报对业务指标的提升。一个实验通常由一两个算法工程师负责，如果有提升，那么就是算法工程师自己的业绩。
- 公司需要考察一个部门在一段时间内对业务指标总体的提升，比如推荐部门在两个月内的成果。不能简单地把所有推荐指标的收益都加起来作为部门整体业绩，这样相加是不可信的。实验叠加到一起通常会有折损。
- 所有需要holdout机制，取10%的用户作为holdout桶，推荐系统使用剩余90%的用户做实验，两者互斥。
- 只要算一下两者（10%holdout桶和90%实验桶）的diff（需要归一化）即可作为整个部门的业务指标收益。
- 在每个考核周期结束之后，会清除holdout桶，让退全实验从90%的用户扩大到100%的用户。
- 然后随机重新划分用户，得到holdout桶和实验桶，开始下一轮考核周期。
- 由于划分是随机均匀的，新的holdout桶与实验桶各种业务指标diff接近0，可以开始公平实验对比。
- 在新的考核周期开始之后，会有召回，粗排，精排，重排的实验上线和推全，diff会之间扩大。

这节课随后一部分内容是**实验推全&反转实验**：

推荐系统中所有实验都是从小流量开始的，如果业务指标显著正向，则可以推全实验。举个例子，我们做一个重排策略实验，取一个桶作为实验组，一个桶作为对照组，实验一共影响了20%的用户，如果观测到显著正向的业务指标收益，则可以推全这个策略，把重排层实验过点，这样就能把两个桶空出来给其他实验用。推全的时候新开一层，新策略会影响全部90%的用户。在小流量阶段，新策略作用到10%用户上，会微弱地提升实验桶和holdout桶的diff。推全之后，新策略作用到90%用户上，diff会扩大9倍。比方说AB测试发现新策略会提升点击率9个万分点，小流量实验之作用到10%的用户上，所以只能把和holdout桶的diff提升1个万分点，推全之后，理论上可以把diff提升到9个万分点，跟AB测试得到的数据一致。

接下来讲反转实验。上线一个有效的策略之后，需要观测很多业务指标：

有的指标（点击，交互类如点赞、完播）会立刻收到新策略的影响，而有的指标（留存）有滞后性，需要长期观测。比如点击率、点赞率等指标会立刻收到新策略的影响，实验上线一天或者实验上线十天，观测到的指标差距不会太大。用户使用的时长，人均阅读量这些指标有些滞后，需要多观察几天指标才会稳定。用户留存指标滞后非常严重，有可能短期内观测不到显著变化，但在之后几个月会持续改善。指标滞后的原因不难理解，新策略改善用户体验，过一段时间才能倍用户感受到，感受到之后，用户对产品的粘性越来越高。也就是说，实验观测的越久越好，可以让观测到的指标跟准确。

但算法工程师希望在观测到显著收益之后，一两周就推全实验。这样有很多好处，可以腾出桶来给其他实验使用，活需要机遇新策略做后续实验开发。也就是说尽快推全有好处，实验保留很久很也有好处，这就是一对矛盾。实践中常用反转实验解决上述矛盾，既可以尽快推全，也可以长期观测实验指标。具体做法是在推全的新层开一个旧策略的桶，这样就可以长期观测实验指标。

我画一下反转实验的示意图，这是为推全新策略开的一层，新层与召回、粗排、精排、重拍全部正交，可以在这个新层里开一个很小的反转桶，桶里的用户都用旧策略。可以把反转桶保留很久，长期观察新策略与旧策略的diff。一个考核周期结束之后，会清除掉holdout桶，但这不会影响反转桶。清除holdout会把推全的新策略作用到holdout用户上，不会影响反转桶。当反转实验完成时，关闭反转实验，新策略会作用到反转桶的用户上，也就是实验真正推全，对所有用户都生效.

总结：
- 分层实验是工业界通用的做法，把容易相互增强或抵消的实验放在同一层。同层互斥（不允许两个实验同时影响一位用户），不同层正交（不同实验可以有重叠的用户）。
- Holdout也是工业界通用的机制，保留10%用户，完全不受实验影响，可以考察整个部门在两个月内对业务指标的总的贡献。
- 实验推全，意思是流量扩到到90%用户，每新建一个策略都会新建一个推全层，覆盖90%用户，与其他层正交。
- 反转实验，是为了尽早推全新策略的同时可以长期观察各种指标。具体做法是在新的推全层上，保留一个小反转桶，使用旧策略，可以把反转桶保留很久，长期观测新旧策略的diff。

## <span>召回</span><a id="召回"></a>
### <span style="font-size:smaller; color:LightCoral">召回01</span> 基于物品的协同过滤（ItemCF）

用一个通俗的例子解释ItemCF的原理：比方说我喜欢看《笑傲江湖》，《笑傲江湖》与《鹿鼎记》相似，而且我没有看过《鹿鼎记》，那么系统会给我推荐《鹿鼎记》。推荐的理由是两个物品很相似。系统通过历史记录可以知道我喜欢看《笑傲江湖》，而求没看到过《鹿鼎记》，但是推荐系统如何知道《笑傲江湖》与《鹿鼎记》相似呢？有很多种办法可以做到，比如用知识图谱，两本书的作者相同，所以两本书相似；还可以基于全体用户的行为判断物品的相似性，比如看过《笑傲江湖》的用户也看过《鹿鼎记》，给《笑傲江湖》写好评的用户也给《鹿鼎记》写好评，我们可以从用户的行为中挖掘出物品的相似性，用物品之间的相似性做推荐。

下面讲解**ItemCF的实现**：每个用户都交互过若干个物品，比如点击、点赞、收藏、转发过的物品。可以量化用户对物品的兴趣，比如点击、点赞、收藏、转发这四种行为个算一分。在这个例子中，用户对四个物品的兴趣分数$like(user, item_j)$分别是2，1，4，3。对于用户没有交互过的候选物品，我们要决定是否把这个物品推荐给用户。假设我们知道物品两两之间的相似度，比如他们的相似度$sim(item_j, item)$分别是0.1,0.4,0.2,0.6,后面会详细讲解相似度是如何计算的，用下面的公式来预估**用户对候选物品的兴趣**：

$$\sum_j like(user, item_j) \times sim(item_j, item)$$

在这个例子中，从用户到候选物品有4个路径，所以要计算四个分数把他们相加，计算$2 \times 0.1 + 1 \times 0.4 + 4 \times 0.2 + 3 \times 0.6 = 3.2$，表示用户对候选物品的兴趣。举个例子，有2000个候选物品，我们逐一计算用户对候选物品的兴趣分数，然后返回其中分数最高的100个物品。

我们来看看具体如何计算两个物品的相似度：
- 两个物品的受众重合度越高，两个物品越相似。我们可以从数据中挖掘出物品的相似度。
- 相似例子：喜欢《射雕英雄传》和《神雕侠侣》的读者重合度很高，因此可以认为《射雕英雄传》和《神雕侠侣》相似。
- 不相似例子：下面是一些用户，这些边表示用户喜欢物品，红色和绿色这两个物品的受众没有重合，这意味着两个物品不相似。蓝色和绿色的物品被判定为相似，这是因为两个物品的受众重合度非常高。

计算**物品相似度**：
- 喜欢物品$i_1$的用户记作集合$W_1$，喜欢物品$i_2$的用户记作集合$W_2$。
- 集合$W_1$和$W_2$的交集记作$V = W_1 \cap W_2$, $V$包含同时喜欢$i_1$和$i_2$的用户。
- $i_1$和$i_2$两个物品的相似度：

$$sim(i_1, i_2)= \frac{\lvert V \rvert}{\sqrt{\lvert W_1 \rvert \cdot \lvert W_2 \rvert}}$$

分子是集合$V$的大小，即对两个物品都感兴趣的人数，$V$类似。这样计算出的相似度一定是一个介于0到1之间的数（因为$V$的数值一定比$W_1$和$W_2$小），数值越大表示两个物品月相似。注意，这个公式没有考虑喜欢的程度$like(user, item)$。用这个公式，只要是喜欢就看做1，不喜欢就看做0。

- 如果想要用到喜欢的程度，需要改一下这个公式。比如点击、点赞、收藏、转发各自算1分，用户对物品的喜欢程度最多是4分。现在我们考虑用户对物品的喜欢程度：

$$sim(i_1, i_2)= \frac{\sum_{v \in V}like(v, i_1) \cdot like(v, i_2)}{\sqrt{\sum_{u_1 \in W_1} like^2(u_1, i_1)} \cdot \sqrt{\sum_{u2 \in W_2} like^2(u_2, i_2)}}$$

分子把用户$v$对物品$i_1$和$i_2$的兴趣分数相乘取连加，连加是关于用户$v$取的，用户$v$同时喜欢两个物品。如果兴趣分数的取值是0或者1，那么分子就是同时喜欢两个物品的人数，也就是集合$V$的大小。公式的分母是两个根号的乘积，第一项是用户对物品$i_1$的兴趣分数的平方关于所有用户求连加然后开根号，第二项类似用户对物品$i_2$的兴趣分数的平方关于所有用户求连加然后开根号。这个公式计算出的数值介于0到1之间，表示两个物品的相似度。其实这个公式就是**余弦相似度（cosine similarity）**，把一个物品表示为一个向量，向量每个元素对应一个用户，元素的指就是用户对物品的兴趣分数，两个向量的夹角的余弦就是这个公式。

小结：
- ItemCF的基本思想是根据物品的相似度做推荐，如果用户喜欢物品$i_1$，而且物品$i_1$与物品$i_2$相似，那么用户很可能喜欢物品$i_2$。
- 做推荐就需要预估用户对候选物品的兴趣有多强，给每个物品打一个分数，把分数高的物品推荐给用户。上面列出了预估兴趣分数的公式，需要用到用户的历史行为记录，对各个物品的兴趣，我们还需要知道物品$j$与候选物品的相似度，把两个数相乘，然后关于物品$j$取连加，作为用户对候选物品兴趣的预估。
- 这个公式需要知道物品两两之间的相似度，我们事先计算然后保存起来。上面列出了计算物品相似度的公式。

下面讲解**ItemCF召回的完整流程**：为了能在线上做到实时的推荐，系统必须要事先做离线计算，建立两个索引。

一个索引是“用户->物品”的索引：
- 记录每个用户最近点击、交互过的物品ID，比如最近交互过的两百个物品，每个物品还有相应的兴趣分数。
- 有了这个索引之后，给定任意用户ID，可以快速返回他近期感兴趣的物品列表。

另一个索引是“物品->物品”的索引：
- 我们首先要计算物品之间两两相似度，这个计算量会比较大。
- 对于每个物品，索引它最相似的k个物品，比如k=10或k=100。
- 有了这个索引之后，给定任意物品ID，可以快速返回与它最相似的k个物品，而且知道相似度分数。

有了索引之后，我们可以在线上给用户做实时推荐。比如：
1. 现在有个用户刷小红书，系统知道这个用户的ID，首先查看“用户->物品”索引，可以快速找到用户近期感兴趣的物品列表（last-n）。
2. 对于last-n集合中的每个物品，通过“物品->物品”的索引，找到top-k相似物品。因此，一用返回nk个物品。
3. 对于取回的相似物品（最多有nk个），用公式预估用物对物品的兴趣分数。
4. 按照分数从高到低对物品做排序，返回分数最高的100个物品，这一百个物品就是itemCF这个召回通道的输出，会跟其他召回通道的输出融合起来，然后做排序，最终展示给用户。

为什么要用索引呢？数据库有上亿个物品，如果挨个计算用户对所有物品的兴趣，计算量会爆，索引的意义在于避免枚举所有的物品。加入我们记录用户最近感兴趣的n=200个物品，取回每个物品最相似的k=10个物品，那么一共取回nk=2000个物品，用公式给这2000个物品打分（用户对物品的兴趣分数），返回分数最高的100个物品作为ItemCF通道的输出。这样的计算量是很小的，可以做到在线实时计算。总结一下，用索引的话，离线计算量大并需要更新两个索引，好处是线上计算量小，召回很快。这节课介绍 Swing 模型，它跟 ItemCF 非常类似，唯一

### <span style="font-size:smaller; color:LightCoral">召回02</span> Swing模型
这节课介绍ItemCF的一个变体，叫做Swing，在工业界很常用。Swing跟ItemCF非常像，区别就是怎样定义物品的相似度。

此处省略recap on ItemCF的原理。下面讲ItemCF的不足之处，问题在于假如重合的用户是一个小圈子该怎么办。比方说这四个用户（四个用户都喜欢了item 1 和 item 2）都在同一个微信群里面，左边的item 1是这样的一篇笔记《某网站护肤品打折》，右边的物品item 2是笔记《字节裁员了》。这两篇笔记没有什么相似之处，他们的受众差别很大，但是两边笔记碰巧被分享到同一个微信群，群里有很多人同时点开这两篇笔记。这样就造城一个问题，两篇笔记的受众完全不同，但是很多用户同时交互过这两篇笔记，导致系统错误得判断两篇笔记的相似度很高。

想要解决这个问题，降低小圈子用户的权重，我们希望两个物品重合的用户广泛而且多样，而不是集中在一个小圈子里。一个小圈子的用户同时交互两个物品不能说明两个物品相似；反过来，如果大量不相关的用户同时交互两个物品，则说明两个物品有相同的受众。Swing的原理就是给用户设置权重，解决小圈子问题。

接下来讲Swing模型是怎么计算两个物品的相似度：
- 用户$u_1$喜欢的物品记作集合$J_1$
- 用户$u_2$喜欢的物品记作集合$J_2$
- 定义两个用户的重合度为$J_1$与$J_2$交集的大小，记作：

$$overlap(u_1, u_2) = \lvert J_1 \cap J_2 \rvert$$

- 用户$u_1$和$u_2$的重合度越高，则他们越有可能是一个小圈子的人，要降低他们的权重。在计算物品相似度的时候，会把$overlap(u_1, u_2)$放到分母上。

Swing模型：
- 喜欢物品$i_1$的用户记作$W_1$，喜欢物品$i_2$的用户记作$W_2$
- 定义交集$V = W_1 \cap W_2$
- 两个物品的相似度

$$sim(i_1, i_2) = \sum_{u_1 \in V} \sum_{u_2 \in V} \frac{1}{\alpha + overlap(u_1, u_2)}$$

$\alpha$是一个人共设置的参数，需要调。如果两个人来自一个小圈子，重叠大，那么他们两个人对相似度的贡献比较小；反过来，如果overlap小，那他们对相似度的贡献比较大。用overlap可以降低小圈子对相似度的影响。

总结：
- Swing与ItemCF唯一的区别在于物品相似度
- ItemCF：两个物品重合的用户比例高，则判定两个物品相似
- Swing：额外考虑重合的用户是否来自于一个小圈子
    - 两个用户overlap大，则可能来一个小圈子，权重降低

### <span style="font-size:smaller; color:LightCoral">召回03</span> 基于用户的协同过滤（UserCF）
UserCF和ItemCF有很多相似之处，ItemCF是基于物品之间的相似度做推荐，UserCF是基于用户之间的相似度做推荐。

UserCF的**原理**：作为小红书的用户，我在小红书的点击点赞收藏转发可以体现出我的兴趣爱好，小红书上至少有几百个和我兴趣爱好非常相似的网友，虽然我不认识这些网友，但小红书可以从大数据中挖掘出来，小红书知道我们的兴趣爱好非常相似。今天其中某个跟我兴趣爱好非常相似的用户对某笔记点赞转发，于是小红书知道他喜欢这篇笔记，而我没看过这篇笔记，那么推荐系统就有可能给我推荐这篇笔记，推荐的理由就是跟我兴趣爱好的用户喜欢这篇笔记。

推荐系统如何找到跟我兴趣非常相似的网友呢？
- 方法一：点击、点赞、收藏、转发的笔记有很大的重合。每个用户都有一个列表，上面存储了交互过的笔记ID，对比两个用户的列表，就知道有多大的重合，重合越多说明两个人的兴趣越相似。
- 方法二：关注的作者有多大重合。每个用户都会关注一些作者，对比两个用户关注的作者列表，就知道有多少关注的作者是重合的。关注的作者重合越多说明两个人的兴趣越相似。

UserCF的**实现**：在用UserCF做推荐之前，需要先离线算好每两个用户之间的相似度，计算相似度的方法稍后再讲。在这个例子中，我们想要给左边的用户做推荐，右边是最相似的四个用户，用户之间的相似度$sim(user, user_j)=0.9, 0.7, 0.7, 0.4$。右边是候选物品，用户还没有看过这个候选物品，我们想要预估左边的用户对右边的候选物品兴趣有多大。历史数据反映了用户对候选物品的兴趣$like(user_j, item)=0, 1, 3, 0$，0表示用户没有看过该物品或者对物品不感兴趣。用这个公式来预估**用户对候选物品的兴趣**：

$$\sum_j sim(user, user_j) \times like(user_j, item)$$

在这个例子中，从用户到候选物品有4个路径，$0.9 \times 0 + 0.7 \times 1 + 0.7 \times 3 + 0.4 \times 0 = 2.8$，表示左边用户对候选物品的兴趣。举个例子，有2000个候选物品，我们逐一计算用户对候选物品的兴趣分数，然后返回其中分数最高的100个物品。

计算**用户相似度**：这里的相似度指的是有用户有共同的兴趣点。先举个例子什么样两个用户不相似，这个例子中两个用户不相似，他们喜欢的物品没有重合。这个例子中两个用户被判定为相似，这是因为两个用户喜欢的物品重合度非常高，他们的兴趣点相似。两个用户的相似度是这样计算的：
- 用户$u_1$的喜欢的物品记作集合$J_1$，用户$u_2$的喜欢的物品记作集合$J_2$
- 集合$W_1$和$W_2$的交集记作$I = J_1 \cap J_2$, $I$包含两个用户共通喜欢的物品
- $u_1$和$u_2$两个用户的相似度：

$$sim(u_1, u_2)= \frac{\lvert I \rvert}{\sqrt{\lvert J_1 \rvert \cdot \lvert J_2 \rvert}}$$

这个公式有个不足之处，公式同等对待热门和冷门物品，这是不对的。拿书籍推荐举个例子，《哈利波特》是非常热门的物品，不论是大学教授还是中学生都喜欢《哈利波特》，既然所有人都喜欢看《哈利波特》，那么《哈利波特》对于计算用户相似度是没有价值的，越热门的物品越无法反映出用户独特的性质，对计算相似度久没有用；反过来，重合的物品越冷门，越能反映出用户的兴趣，如果两个用户都喜欢《Deep Learning》这本书，说明两个人很有可能是同行，如果两个人都喜欢更冷门些的书《Deep Learning for NLP and Speech Recognition》，说明两个人是小同行。为了更好得计算用户兴趣的相似度，我们需要**降低热门物品的权重**。前面计算用户相似度的公式可以等价改写成这种形式：

$$sim(u_1, u_2)= \frac{\sum_{l \in I} 1}{\sqrt{\lvert J_1 \rvert \cdot \lvert J_2 \rvert}}$$

这里的分子还是集合$I$的大小，只不过换了种写法，写成了对1对连加，连加符号中的$l$是物品的序号，连加中的1是物品的权重，所有物品的权重都相同。刚才我们讨论了物品权重应该跟热门程度相关，越热门应该权重越低。我们把分子中的1换成


$$sim(u_1, u_2)= \frac{\sum_{l \in I} \frac{1}{log(1+n_l)}}{\sqrt{\lvert J_1 \rvert \cdot \lvert J_2 \rvert}}$$


### <span style="font-size:smaller; color:LightCoral">召回04</span> 离散特征处理
### <span style="font-size:smaller; color:LightCoral">召回05</span> 矩阵补充、最近邻查找
### <span style="font-size:smaller; color:LightCoral">召回06</span> 双塔模型--模型结构、训练方法
### <span style="font-size:smaller; color:LightCoral">召回07</span> 双塔模型--正负样本
### <span style="font-size:smaller; color:LightCoral">召回08</span> 双塔模型--线上服务、模型更新
### <span style="font-size:smaller; color:LightCoral">召回09</span> 双塔模型+自监督学习
### <span style="font-size:smaller; color:LightCoral">召回10</span> Deep Retrieval 召回
### <span style="font-size:smaller; color:LightCoral">召回11</span> 地理位置召回、作者召回、缓存召回
### <span style="font-size:smaller; color:LightCoral">召回12</span> 曝光过滤 & Bloom Filter

## <span>排序</span><a id="排序"></a>
### <span style="font-size:smaller; color:LightCoral">排序01</span> 多目标模型
### <span style="font-size:smaller; color:LightCoral">排序02</span> Multi-gate Mixture-of-Experts (MMoE)
### <span style="font-size:smaller; color:LightCoral">排序03</span> 预估分数融合
### <span style="font-size:smaller; color:LightCoral">排序04</span> 视频播放建模
### <span style="font-size:smaller; color:LightCoral">排序05</span> 排序模型的特征
### <span style="font-size:smaller; color:LightCoral">排序06</span> 粗排模型

## <span>特征交叉</span><a id="特征交叉"></a>
### <span style="font-size:smaller; color:LightCoral">特征交叉01</span> Factorized Machine (FM) 因式分解机
### <span style="font-size:smaller; color:LightCoral">特征交叉02</span> DCN深度交叉网络
### <span style="font-size:smaller; color:LightCoral">特征交叉03</span> LHUC (PPNet)
### <span style="font-size:smaller; color:LightCoral">特征交叉04</span> SENet 和 Bilinear 交叉

## <span>行为序列</span><a id="行为序列"></a>
### <span style="font-size:smaller; color:LightCoral">行为序列01</span> 用户历史行为序列建模
### <span style="font-size:smaller; color:LightCoral">行为序列02</span> DIN模型（注意力机制）
### <span style="font-size:smaller; color:LightCoral">行为序列03</span> SIM模型（长序列建模）

## <span>重排</span><a id="重排"></a>
### <span style="font-size:smaller; color:LightCoral">重排01</span> 物品相似性的度量、提升多样性的方法
### <span style="font-size:smaller; color:LightCoral">重排02</span> MMR(Maximal Marginal Relevance)多样性算法
### <span style="font-size:smaller; color:LightCoral">重排03</span> 业务规则约束下的多样性算法
### <span style="font-size:smaller; color:LightCoral">重排04</span> DPP多样性算法（上）
### <span style="font-size:smaller; color:LightCoral">重排05</span> DPP多样性算法（下）

## <span>物品冷启</span><a id="物品冷启"></a>
### <span style="font-size:smaller; color:LightCoral">物品冷启01</span> 优化目标 & 评价指标
### <span style="font-size:smaller; color:LightCoral">物品冷启02</span> 简单的召回通道
### <span style="font-size:smaller; color:LightCoral">物品冷启03</span> 聚类召回
### <span style="font-size:smaller; color:LightCoral">物品冷启04</span> Look-Alike召回
### <span style="font-size:smaller; color:LightCoral">物品冷启05</span> 流量调控
### <span style="font-size:smaller; color:LightCoral">物品冷启06</span> 冷启的AB测试

## <span>涨指标的方法</span><a id="涨指标"></a>
### <span style="font-size:smaller; color:LightCoral">张指标的方法01</span> 概述
### <span style="font-size:smaller; color:LightCoral">张指标的方法02</span> 召回
### <span style="font-size:smaller; color:LightCoral">张指标的方法03</span> 排序模型
### <span style="font-size:smaller; color:LightCoral">张指标的方法04</span> 多样性
### <span style="font-size:smaller; color:LightCoral">张指标的方法05</span> 特殊用户人群
### <span style="font-size:smaller; color:LightCoral">张指标的方法06</span> 交互行为（关注、转发、评论）