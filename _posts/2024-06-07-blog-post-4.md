---
title: 'Notes of 推荐系统公开课 by Shusen Wang'
date: 2024-06-07
permalink: /posts/2024/06/blog-post-4/
tags:
  - learning
  - career
---

Disclaimer: The content herein is sourced from Shusen Wang's YouTube Channel, specifically the Playlist titled [Recommendation System]((https://www.youtube.com/playlist?list=PLvOO0btloRntAi-VnV06M1Bu0X1xljUUP)). This post is intended for personal study purposes.

------

[1 概要](#概要)  
[2 召回](#召回)  
[3 排序](#排序)  
[4 特征交叉](#特征交叉)  
[5 行为序列](#行为序列)  
[7 物品冷启](#物品冷启)  
[8 涨指标的方法](#涨指标)  

------

## <span>概要</span><a id="概要"></a>
### <span style="font-size:smaller; color:LightCoral">概要01</span> 推荐系统的基本概念
转化流程
```
曝光（Impression） --> 点击（Click） --> 滑动到底(ScrowToEnd), 点赞(Like), 收藏(Collect), 转发(Share) --> 评论(Comment)
```

（短期）消费指标：
- 点击率 = 点击次数 / 曝光次数
- 点赞率 = 点赞次数 / 点击次数
- 收藏率 = 收藏次数 / 点击次数
- 转发率 = 转发次数 / 点击次数
- 阅读完成率 = 滑动到底次数 / 点击次数 $\times f$(笔记长度) 

虽然点击率是重要的优化指标，但不能是唯一的指标，否则骗点击的标题就会泛滥。其他指标也可以反映出用户对笔记的兴趣。
$f$(笔记长度) 是一个归一化的函数，这是因为笔记越长，完成阅读的比例就越低。如果没有这个归一化的函数，对长笔记不公平。
注意：一味追求短期消费指标是不对的。举个例子，如果推荐算法只看用户短期兴趣，推很多用户最近感兴趣的内容，这些消费指标上涨，这样的坏处是会竭泽而渔，用户会很快失去兴趣，不再回来；反过来，如果把多样性做好，尝试一些用户没看过的话题，那么点击率不会上涨，但是会有利于提高用户粘性，留住用户，让用户更活跃。

衡量推荐系统的好坏，最重要的指标叫北极星指标，即最关键的指标，是衡量推荐系统好坏的根本标准。

北极星指标
- 用户规模：DAU， MAU
- 消费：人均使用推荐的时长，人均阅读笔记的数量
- 发布：发布渗透率、人均发布量

实验流程
- 离线实验 
    - 收集历史数据，在历史数据上做训练、测试。算法没有部署到产品中，没有跟用户交互。
    - 结果有参考价值，但没有线上实验可靠，也无法得到线上指标。
- 小流量AB测试
    - 算法部署到实际产品中，用户实际跟算法做交互。
    - 可以得到线上指标，如北极星指标。
- 全流量上线

### <span style="font-size:smaller; color:LightCoral">概要02</span> 推荐系统的链路
```
--几亿物品--> 召回 --几千物品--> 粗排 --几百物品--> 精排 --几百物品--> 重排 --几十物品-->
```

- 召回
    - 当用户刷新小红书时，系统会同时调用几十条召回通道，每条召回通道取几十到几百笔记，一共取几千篇笔记
- 粗排
    - 用规模比较小的机器学习模型给几千篇笔记逐一打分，按照分数做排序和截断，保留分数最高的几百篇笔记
- 精排
    - 这里要用大规模的神经网络为几百篇笔记逐一打分，精排的分数反映出用户对笔记的兴趣
    - 精排之后，可以做截断，也可以不做截断。小红书的精排不做截断，几百篇笔记都带着精排分数进入重排
- 重排
    - 重排是最后一步，根据精排分数和多样性分数做随机抽样，得到几十篇笔记
    - 然后把相似内容打散，并且插入广告和运营内容
    - 重拍的规则非常复杂，有好几千行代码

粗排、精排的NN输入是用户特征，物品特征，和统计特征，NN输出点预估的击率，点赞率，收藏率，转发率。融合（加权和）预估值得到最终的排序分数。这个值会决定笔记是否会被展示给用户，靠前或靠后。重排最重要的是做多样性抽样，比如MMR、DPP，从几百篇中选出几十篇。抽样的时候有两个依据，一个是精排分数的大小，一个是多样性。做完抽样后，用规则打散相似笔记，我们不能把内容过于相似的笔记排在相邻的位置上。重排的另一个目的是插入广告、运营推广内容，根据生态要求调整排序，比如不能连着出美女图片。召回和粗排是最大的漏斗，它们让候选笔记的数量从几亿变成几千然后变成几百。当候选笔记之后几百才能用大规模NN做精排，用DPP做抽样。

### <span style="font-size:smaller; color:LightCoral">概要03</span> 推荐系统的AB测试

算法工程师的日常工作就是改进算法的策略，目标是提高推荐系统的业务指标。所有对模型的粗略的改进都需要进行线上的AB测试，用实验数据来验证试验策略是否有效。举个例子解释AB测试的目的是什么：
- 召回团队实现了一种GNN召回通道，离线实验结果正向。但是离线实验的指标有提升未必意味着线上实验也会有收益。
- 做完离线实验，下一步是做线上的小流量AB测试，考察新的召回通道对线上指标的影响，比如DAU，留存，交互等。
- 除了上述目的，模型中的一些参数，比如GNN的深度取值（1，2，3），需要用AB测试选取最优参数。可以同时开三组AB测试，哪组效果好用哪个。

做AB测试需要对用户做随机分桶，比方说：
- 分$b=10$个桶，每个桶中有10%的用户。如果用户的数量足够大，那么每个桶DAU，留存，点击率这些指标都是相等的。
- 首先用哈希函数把用户ID映射成某个区间内的整数，然后把这些整数随机分成$b$个桶。
- 以GNN为例，一号桶实验组#1，以此类推，四号桶为对照组
- 计算每个桶的业务指标，比如DAU，人均使用推荐的时长，点击率等。
- 如果某个实验组指标显著优于对照组，则说明对应的策略有效，值得推全，即把流量扩大到100%。

接下来讲分层实验，用业界实际上就是这么做的。分层实验的目标就是解决流量不够用的问题。举个例子解释，比方说小红书有很多个部门，每个部门有好几个团队，负责推荐系统（召回，粗排，精排，重排），用户界面，广告，所有团队同时需要做实验，线上需要做几十个甚至上百个实验。如果把用户随机分成10组，1组作对照，9组作实验，那么只能同时做9组实验，根本无法满足产品迭代的需求。解决方案就是分层实验：
- 把实验分成很多层，比如召回，粗排，精排，重排，用户界面，广告，...
- 同层是实验之间需要互斥：比如GNN实验占了召回层的4个桶，其他召回实验只能用剩余的6个桶。同层互斥的目的是避免一个用户同时被两个召回实验影响。如果两个实验相互干扰，实验结果会变的不可控。
- 不同层之间流量正交：每一层都独立随机对用户做分桶。每一层都可以独立用100%的用户做实验。召回和粗排的用户是独立随机划分的，召回的2号桶和粗排的2号桶交集很小。
- 分层实验参考文献 Tang et al. Overlapping experiment infrastructure: more, better, faster experimentation. In KDD, 2020. [PDF](https://dl.acm.org/doi/pdf/10.1145/1835804.1835810) 

举个例子，召回层和精排层各自独立随机把用户分成10个桶：
- 召回层把用户分成10个桶：$u_1, u_2, ..., u_{10}$
- 精排层把用户分成10个桶：$v_1, v_2, ..., v_{10}$
- 设系统一共有$n$个用户，那么$\lvert u_i \rvert=\lvert v_j \rvert=n/10$
- 召回桶$u_i$和召回桶$u_j$的交集为$u_i \cap u_j=\varnothing$，即同层互斥，两个召回实验不会同时作用到同一用户上。
- 召回桶$u_i$和精排桶$v_j$的交集的大小为$\lvert u_i \cap v_j \rvert =n/100$。一个用户不能同时被两个召回实验影响，但可以同时受一个召回实验和一个精排实验影响。一个召回实验和一个精排实验各自作用在$n/10$个用户上，那么有$n/100$的用户同时被召回实验和精排实验影响，即不同层正交。

互斥 vs 正交：
- 如果所有实验都正交，则可以同时做无数组实验。
- 同类的策略（例如精排模型的两种结构）天然互斥，对于一个用户，只能用其中一种。
- 同类的策略（例如添加两条召回通道）效果会相互增强（1+1>2）。互斥可以避免同类策略相互干扰。
- 不同类型的策略（例如添加召回通道、优化粗排模型）通常不会相互干扰（1+1=2），可以作为正交的两层。

前面讲了AB测试的原理和分层实验，接下来介绍holdout机制：
- 每个实验（召回，粗排，精排，重排）独立汇报对业务指标的提升。一个实验通常由一两个算法工程师负责，如果有提升，那么就是算法工程师自己的业绩。
- 公司需要考察一个部门在一段时间内对业务指标总体的提升，比如推荐部门在两个月内的成果。不能简单地把所有推荐指标的收益都加起来作为部门整体业绩，这样相加是不可信的。实验叠加到一起通常会有折损。
- 所有需要holdout机制，取10%的用户作为holdout桶，推荐系统使用剩余90%的用户做实验，两者互斥。
- 只要算一下两者（10%holdout桶和90%实验桶）的diff（需要归一化）即可作为整个部门的业务指标收益。
- 在每个考核周期结束之后，会清除holdout桶，让退全实验从90%的用户扩大到100%的用户。
- 然后随机重新划分用户，得到holdout桶和实验桶，开始下一轮考核周期。
- 由于划分是随机均匀的，新的holdout桶与实验桶各种业务指标diff接近0，可以开始公平实验对比。
- 在新的考核周期开始之后，会有召回，粗排，精排，重排的实验上线和推全，diff会之间扩大。

这节课随后一部分内容是实验推全&反转实验：

推荐系统中所有实验都是从小流量开始的，如果业务指标显著正向，则可以推全实验。举个例子，我们做一个重排策略实验，取一个桶作为实验组，一个桶作为对照组，实验一共影响了20%的用户，如果观测到显著正向的业务指标收益，则可以推全这个策略，把重排层实验过点，这样就能把两个桶空出来给其他实验用。推全的时候新开一层，新策略会影响全部90%的用户。在小流量阶段，新策略作用到10%用户上，会微弱地提升实验桶和holdout桶的diff。推全之后，新策略作用到90%用户上，diff会扩大9倍。比方说AB测试发现新策略会提升点击率9个万分点，小流量实验之作用到10%的用户上，所以只能把和holdout桶的diff提升1个万分点，推全之后，理论上可以把diff提升到9个万分点，跟AB测试得到的数据一致。

接下来讲反转实验。上线一个有效的策略之后，需要观测很多业务指标：

有的指标（点击，交互类如点赞、完播）会立刻收到新策略的影响，而有的指标（留存）有滞后性，需要长期观测。比如点击率、点赞率等指标会立刻收到新策略的影响，实验上线一天或者实验上线十天，观测到的指标差距不会太大。用户使用的时长，人均阅读量这些指标有些滞后，需要多观察几天指标才会稳定。用户留存指标滞后非常严重，有可能短期内观测不到显著变化，但在之后几个月会持续改善。指标滞后的原因不难理解，新策略改善用户体验，过一段时间才能倍用户感受到，感受到之后，用户对产品的粘性越来越高。也就是说，实验观测的越久越好，可以让观测到的指标跟准确。

但算法工程师希望在观测到显著收益之后，一两周就推全实验。这样有很多好处，可以腾出桶来给其他实验使用，活需要机遇新策略做后续实验开发。也就是说尽快推全有好处，实验保留很久很也有好处，这就是一对矛盾。实践中常用反转实验解决上述矛盾，既可以尽快推全，也可以长期观测实验指标。具体做法是在推全的新层开一个旧策略的桶，这样就可以长期观测实验指标。

我画一下反转实验的示意图，这是为推全新策略开的一层，新层与召回、粗排、精排、重拍全部正交，可以在这个新层里开一个很小的反转桶，桶里的用户都用旧策略。可以把反转桶保留很久，长期观察新策略与旧策略的diff。一个考核周期结束之后，会清除掉holdout桶，但这不会影响反转桶。清除holdout会把推全的新策略作用到holdout用户上，不会影响反转桶。当反转实验完成时，关闭反转实验，新策略会作用到反转桶的用户上，也就是实验真正推全，对所有用户都生效.

总结：
- 分层实验是工业界通用的做法，把容易相互增强或抵消的实验放在同一层。同层互斥（不允许两个实验同时影响一位用户），不同层正交（不同实验可以有重叠的用户）。
- Holdout也是工业界通用的机制，保留10%用户，完全不受实验影响，可以考察整个部门在两个月内对业务指标的总的贡献。
- 实验推全，意思是流量扩到到90%用户，每新建一个策略都会新建一个推全层，覆盖90%用户，与其他层正交。
- 反转实验，是为了尽早推全新策略的同时可以长期观察各种指标。具体做法是在新的推全层上，保留一个小反转桶，使用旧策略，可以把反转桶保留很久，长期观测新旧策略的diff。

## <span>召回</span><a id="召回"></a>
### <span style="font-size:smaller; color:LightCoral">召回01</span> 基于物品的协同过滤（ItemCF）

用一个通俗的例子解释ItemCF的原理：比方说我喜欢看《笑傲江湖》，《笑傲江湖》与《鹿鼎记》相似，而且我没有看过《鹿鼎记》，那么系统会给我推荐《鹿鼎记》。推荐的理由是两个物品很相似。系统通过历史记录可以知道我喜欢看《笑傲江湖》，而求没看到过《鹿鼎记》，但是推荐系统如何知道《笑傲江湖》与《鹿鼎记》相似呢？有很多种办法可以做到，比如用知识图谱，两本书的作者相同，所以两本书相似；还可以基于全体用户的行为判断物品的相似性，比如看过《笑傲江湖》的用户也看过《鹿鼎记》，给《笑傲江湖》写好评的用户也给《鹿鼎记》写好评，我们可以从用户的行为中挖掘出物品的相似性，用物品之间的相似性做推荐。

下面讲解ItemCF的实现：每个用户都交互过若干个物品，比如点击、点赞、收藏、转发过的物品。可以量化用户对物品的兴趣，比如点击、点赞、收藏、转发这四种行为个算一分。在这个例子中，用户对四个物品的兴趣分数$like(user, item_j)$分别是2，1，4，3。对于用户没有交互过的候选物品，我们要决定是否把这个物品推荐给用户。假设我们知道物品两两之间的相似度，比如他们的相似度$sim(item_j, item)$分别是0.1,0.4,0.2,0.6,后面会详细讲解相似度是如何计算的，用下面的公示来预估用户对候选物品物品的兴趣：

$$\sum_j like(user, item_j) \times sim(item_j, item)$$

在这个例子中，从用户到候选物品有4个路径，所以要计算四个分数把他们相加，计算$2 \times 0.1 + 1 \times 0.4 + 4 \times 0.2 + 3 \times 0.6 = 3.2$，表示用户对候选物品的兴趣。举个例子，有2000个候选物品，我们逐一计算用户对候选物品的兴趣分数，然后返回其中分数最高的100个物品。

我们来看看具体如何计算两个物品的相似度：
- 两个物品的受众重合度越高，两个物品越相似。我们可以从数据中挖掘出物品的相似度。
- 相似例子：喜欢《射雕英雄传》和《神雕侠侣》的读者重合度很高，因此可以认为《射雕英雄传》和《神雕侠侣》相似。
- 不相似例子：下面是一些用户，这些边表示用户喜欢物品，红色和绿色这两个物品的受众没有重合，这意味着两个物品不相似。蓝色和绿色的物品被判定为相似，这是因为两个物品的受众重合度非常高。

计算物品相似度：
- 喜欢物品$i_1$的用户记作集合$W_1$，喜欢物品$i_2$的用户记作集合$W_2$。
- 集合$W_1$和$W_2$的交集记作$V = W_1 \cap W_2$, $V$包含同时喜欢$i_1$和$i_2$的用户。
- $i_1$和$i_2$两个物品的相似度：

$$sim(i_1, i_2)= \frac{\lvert V \rvert}{\sqrt{\lvert W_1 \rvert \cdot \lvert W_2 \rvert}}$$

分子是集合$V$的大小，即对两个物品都感兴趣的人数，$V$类似。这样计算出的相似度一定是一个介于0到1之间的数（因为$V$的数值一定比$W_1$和$W_2$小），数值越大表示两个物品月相似。注意，这个公式没有考虑喜欢的程度$like(user, item)$。用这个公式，只要是喜欢就看做1，不喜欢就看做0。

- 如果想要用到喜欢的程度，需要改一下这个公式。比如点击、点赞、收藏、转发各自算1分，用户对物品的喜欢程度最多是4分。现在我们考虑用户对物品的喜欢程度：

$$sim(i_1, i_2)= \frac{\sun_{v \in V}like(v, i_1) \cdot like{v, i_2}}{\sqrt{\sum_{u_1 \in W_1} like^2(u_1, i_1)} \cdot \sqrt{\sum_{u2 \in W_2} like^2(u_2, i_2)}}$$


### <span style="font-size:smaller; color:LightCoral">召回02</span> Swing模型
### <span style="font-size:smaller; color:LightCoral">召回03</span> 基于用户的协同过滤（UserCF）
### <span style="font-size:smaller; color:LightCoral">召回04</span> 离散特征处理
### <span style="font-size:smaller; color:LightCoral">召回05</span> 矩阵补充、最近邻查找
### <span style="font-size:smaller; color:LightCoral">召回06</span> 双塔模型--模型结构、训练方法
### <span style="font-size:smaller; color:LightCoral">召回07</span> 双塔模型--正负样本
### <span style="font-size:smaller; color:LightCoral">召回08</span> 双塔模型--线上服务、模型更新
### <span style="font-size:smaller; color:LightCoral">召回09</span> 双塔模型+自监督学习
### <span style="font-size:smaller; color:LightCoral">召回10</span> Deep Retrieval 召回
### <span style="font-size:smaller; color:LightCoral">召回11</span> 地理位置召回、作者召回、缓存召回
### <span style="font-size:smaller; color:LightCoral">召回12</span> 曝光过滤 & Bloom Filter

## <span>排序</span><a id="排序"></a>
### <span style="font-size:smaller; color:LightCoral">排序01</span> 多目标模型
### <span style="font-size:smaller; color:LightCoral">排序02</span> Multi-gate Mixture-of-Experts (MMoE)
### <span style="font-size:smaller; color:LightCoral">排序03</span> 预估分数融合
### <span style="font-size:smaller; color:LightCoral">排序04</span> 视频播放建模
### <span style="font-size:smaller; color:LightCoral">排序05</span> 排序模型的特征
### <span style="font-size:smaller; color:LightCoral">排序06</span> 粗排模型

## <span>特征交叉</span><a id="特征交叉"></a>
### <span style="font-size:smaller; color:LightCoral">特征交叉01</span> Factorized Machine (FM) 因式分解机
### <span style="font-size:smaller; color:LightCoral">特征交叉02</span> DCN深度交叉网络
### <span style="font-size:smaller; color:LightCoral">特征交叉03</span> LHUC (PPNet)
### <span style="font-size:smaller; color:LightCoral">特征交叉04</span> SENet 和 Bilinear 交叉

## <span>行为序列</span><a id="行为序列"></a>
### <span style="font-size:smaller; color:LightCoral">行为序列01</span> 用户历史行为序列建模
### <span style="font-size:smaller; color:LightCoral">行为序列02</span> DIN模型（注意力机制）
### <span style="font-size:smaller; color:LightCoral">行为序列03</span> SIM模型（长序列建模）

## <span>重排</span><a id="重排"></a>
### <span style="font-size:smaller; color:LightCoral">重排01</span> 物品相似性的度量、提升多样性的方法
### <span style="font-size:smaller; color:LightCoral">重排02</span> MMR(Maximal Marginal Relevance)多样性算法
### <span style="font-size:smaller; color:LightCoral">重排03</span> 业务规则约束下的多样性算法
### <span style="font-size:smaller; color:LightCoral">重排04</span> DPP多样性算法（上）
### <span style="font-size:smaller; color:LightCoral">重排05</span> DPP多样性算法（下）

## <span>物品冷启</span><a id="物品冷启"></a>
### <span style="font-size:smaller; color:LightCoral">物品冷启01</span> 优化目标 & 评价指标
### <span style="font-size:smaller; color:LightCoral">物品冷启02</span> 简单的召回通道
### <span style="font-size:smaller; color:LightCoral">物品冷启03</span> 聚类召回
### <span style="font-size:smaller; color:LightCoral">物品冷启04</span> Look-Alike召回
### <span style="font-size:smaller; color:LightCoral">物品冷启05</span> 流量调控
### <span style="font-size:smaller; color:LightCoral">物品冷启06</span> 冷启的AB测试

## <span>涨指标的方法</span><a id="涨指标"></a>
### <span style="font-size:smaller; color:LightCoral">张指标的方法01</span> 概述
### <span style="font-size:smaller; color:LightCoral">张指标的方法02</span> 召回
### <span style="font-size:smaller; color:LightCoral">张指标的方法03</span> 排序模型
### <span style="font-size:smaller; color:LightCoral">张指标的方法04</span> 多样性
### <span style="font-size:smaller; color:LightCoral">张指标的方法05</span> 特殊用户人群
### <span style="font-size:smaller; color:LightCoral">张指标的方法06</span> 交互行为（关注、转发、评论）